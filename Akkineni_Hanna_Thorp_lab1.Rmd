---
title: "Corruption and Parking Violations"
author: "Akkineni, Hanna, Thorp"
date: "September 26, 2016"
output:
  pdf_document: default
---



```{r}
setwd("C:/Users/kevin/OneDrive/School/MIDS/W203 - Statistics for Data Science/Lab 1/W203_lab1_corruption")
#library(car)
#library(grid)
#library(ggplot2)
library(knitr)
library(kableExtra)

load("Corrupt.Rdata")

## Correct Data Problems
#Fix majoritymulsim where value = -1, should be 0
FMcorrupt[FMcorrupt$majoritymuslim == -1 & ! is.na(FMcorrupt$majoritymuslim), "majoritymuslim"] = 0

# Add missing counties.  Reference: https://www.worldatlas.com/aatlas/ctycodes.htm
FMcorrupt[FMcorrupt$wbcode == "ARE", "country"] = "United Arab Emirates"
FMcorrupt[FMcorrupt$wbcode == "CAF", "country"] = "Central African Republic"
FMcorrupt[FMcorrupt$wbcode == "CAN", "country"] = "Canada"
FMcorrupt[FMcorrupt$wbcode == "COL", "country"] = "Columbia"
FMcorrupt[FMcorrupt$wbcode == "ECU", "country"] = "Ecuador"
FMcorrupt[FMcorrupt$wbcode == "JAM", "country"] = "Jamaica"
FMcorrupt[FMcorrupt$wbcode == "LVA", "country"] = "Latvia"
FMcorrupt[FMcorrupt$wbcode == "NOR", "country"] = "Norway"
FMcorrupt[FMcorrupt$wbcode == "PAN", "country"] = "Panama"
FMcorrupt[FMcorrupt$wbcode == "SWE", "country"] = "Sweden"
FMcorrupt[FMcorrupt$wbcode == "TUR", "country"] = "Turkey"

# Create named regions variable using region
FMcorrupt$region_name = NA
FMcorrupt[FMcorrupt$region == 1 & ! is.na(FMcorrupt$region), "region_name"] = "Caribbean"
FMcorrupt[FMcorrupt$region == 2 & ! is.na(FMcorrupt$region), "region_name"] = "South America"
FMcorrupt[FMcorrupt$region == 3 & ! is.na(FMcorrupt$region), "region_name"] = "Europe"
FMcorrupt[FMcorrupt$region == 4 & ! is.na(FMcorrupt$region), "region_name"] = "Asia" # "South Asia"
FMcorrupt[FMcorrupt$region == 5 & ! is.na(FMcorrupt$region), "region_name"] = "Oceania"
FMcorrupt[FMcorrupt$region == 6 & ! is.na(FMcorrupt$region), "region_name"] = "Africa"
FMcorrupt[FMcorrupt$region == 7 & ! is.na(FMcorrupt$region), "region_name"] = "Middle East" # "Western Asia"

FMcorrupt$region_name = factor(FMcorrupt$region_name)

# Remove 66 rows that do not have relevant data to the key analyses
corrupt = subset(FMcorrupt, !is.na(violations) & !is.na(mission) & !is.na(staff) )


# split data in to pre and post, before and after enforcement changes
cor_pre = subset(corrupt, prepost == "pre")
cor_pos = subset(corrupt, prepost == "pos")

# Merge both the above to one line with pre and pos appeneded to variable names (prepos removed)
cor_oneline = merge(cor_pre, cor_pos, by = "wbcode", suffixes = c(".pre", ".pos"))

# Grab only the variables that are needed.
cor_oneline = cor_oneline[, c("wbcode", "violations.pre",  "violations.pos", "fines.pre", "fines.pos",
                              "mission.pre", "staff.pre", "spouse.pre", "gov_wage_gdp.pre", "pctmuslim.pre", "majoritymuslim.pre", "trade.pre",
                              "cars_total.pre", "cars_mission.pre", "pop1998.pre", "gdppcus1998.pre", "ecaid.pre", "milaid.pre", "corruption.pre", "totaid.pre",
                              "r_africa.pre", "r_middleeast.pre", "r_europe.pre", "r_southamerica.pre", "r_asia.pre",
                              "country.pre", "distUNplz.pre",
                              "region.pre", "region_name.pre"
                              )]

# Remove suffix where not needed. 
colnames(cor_oneline) =  c("wbcode", "violations.pre",  "violations.pos", "fines.pre", "fines.pos",
                              "mission", "staff", "spouse", "gov_wage_gdp", "pctmuslim", "majoritymuslim", "trade",
                              "cars_total", "cars_mission", "pop1998", "gdppcus1998", "ecaid", "milaid", "corruption", "totaid",
                              "r_africa", "r_middleeast", "r_europe", "r_southamerica", "r_asia",
                              "country", "distUNplz",
                              "region", "region_name"
                              )

# Rename FMcorrupt to ensure we don't use it accidentally
cor_nas = FMcorrupt
remove(FMcorrupt)
```

<!-- INTRODUCTION BEGIN -->

# Introduction

## Research Question
Prior to 2002 diplomats at UN missions were exampt from parking violations and fines in New York City, by virtue of their diplomatic immunity. There was wide variation in diplomats' willingness to adhere to local parking laws. This analysis attempts to understand whether the variation in adherance to local parking law was related to cultural norms in the diplomats' home countries. For the period prior to 2002, we examine the relationship between perceptions of corruption in that country and  that countries' diplomats' willingness to incur parking violations. In 2002 NYC parking enforcement acquired the right to confiscate license plates from vehicles belonging to foreign diplomats if they had accumulated unpaid parking violations, thus making payment an function of both cultral norms and legal enforcment. This had a notable compressing effect on parking law adherence. 
 
<b>Question:</b> Does an index of perceived corruption in the diplomats' home country have explanatory power for a given diplomatic mission's compliance with local parking regulations? 

## Description of Dataset

Our data set has a total of 364 observations. Of the 364, 66 observations contain only economic data leaving NA for our dependent variable, violations. Considering the countries that are among these 66 and the variables for which they have valid data, we suspect these rows result from a merge of economic data with the violations data ($econmic\cup violations$). As such, we believe these 66 countries represent a data artefact from that data merge. As these observations do not contain valid values for key variables, we remove them from our dataset. Of note, those 66 observations appear to contain many which do not even have a mission or staff in New York City, and as such are not relevant for this study on diplomatic parking violations in New York City. Given these considerations, we feel comfortable that we are not biasing the results of the study by remiving these observations. With those 66 rows removed, we're left with 298 observations (two observations for each of 149 countries where corruption data exists.) Each country has one observation from prior to the 2002 regulation change and one observation from after. Only the 'violations' and 'fines' variables differ between the two observations for a given country, while other variables remain constant. 

<!-- END INTRODUCTION -->
<!-- BEGIN UNIVARIATE ANALYSIS OF KEY VARIABLES --> 
<!--
Univariate Analysis of Key Variables (20 pts)
Use visualizations and descriptive statistics to perform a univariate analysis of each key variable. Be sure to
describe any anomalies, coding issues, or potentially erroneous values. Explain how you respond to each issue
you identify. Note any features that appear relevant to statistical analysis. Discuss what transformations
may be appropriate for each variable.
-->
# Univariate Analysis of Key Variables

Key Variables:

* violations
* staff
* trade.   (((((((((((((((((((((((((((((((why do we think this is a key variable?))))))))))))))))))))))))))))))



```{r results="asis"}
# Use CSV version of Google Sheet 'Variable Description for Introduction': https://docs.google.com/spreadsheets/d/1cas_xxfaAY5CNGDAvBqa4ky5b8m61i3qTSgN4LrHT_g/edit#gid=621892365
variable_description = read.csv("Lab 1 - Variable Descriptions for Introduction.csv", header = TRUE, sep = ",", quote = "\"", allowEscapes = TRUE)
#summary(variable_description)

kable(variable_description, "latex", longtable = TRUE, booktabs = TRUE, caption = "Data Set Variables") %>%
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position", "striped", "repeat_header"), row_label_position = 1)   

```


#Alex notes to be incorporated above

"""Data quality issues:  
~~1) We have several extra observations that have NaN values for key variables. These data likely reflect a merging 
process wherein the desired dataset regarding parking violations and fines was merged with economic data. 
+wbcode is impacted by this. There are 213 unique values for wbcode, whereas there are only 151 countries with pre and post-legislation 
observations
++++Suggestion: We drop the N/A variables and note the number of countries for which we have no data.~~

2) The violations and fines data are odd. The instructions do not provide adequate background regarding these variables.
This is a particular problem because these variable are at the core of the proposed analysis.
Oddities:
+violations has 7 decimal places. This is odd because we would expect a positive integer (in the case of a single year)
or at least a figure that is recognizable as an average of some sort (in the case of multiple years)  

3) The mission, staff, and spouse variables also contain oddities. For example, the entries for HKG and PRI are 0. These are the only zeros in 
those variables. Looking at the values for other variables for those two observations, some other oddities emerge. For example:
+HKG's majoritymuslim (which should be a dummy variable of either 1 or 0) is -1
++++Suggestion: Given that our research question regards the impact of the corruption on willingness to incur parking
violations and fines in NYC, we probably do not care about observations without a mission in NYC.
As such, taking all of these oddities and the low desirability of the data, I recommend excluding. where 
mission equals 0 or NaN  

4) The variable gov_wage_gdp is not specified in the instructions, and no source for the data is provided. We don't know if this comes from 
an official sector body or from some potentially less rigorous institution. Furthermore, the data appears somewhat disconnected from our 
core violations and fines variables, as there are numerous NaNs for gov_wage_gdp where valid values exist for violations and fines. I do think
the concept that this variable hints at - the impact of government workers' wages on their willingness to occur fines - would be interesting to
examine in relation to the degree of decline from the pre to the post subsets. The thinking being that those government workers with lower average
salaries would be less willing to incur fines out of their own pocket. This is potentially problematic though as it is not clear that the
workers themselves would definitely be the ones paying for the fines. 
++++Suggestion: Given that we don't know the provenance of this dataset nor how it was calculated, I would not treat results using this
dataset with a high degree of confidence. Rather, I would be inclined to largely exclude this variable from the analysis
At most, it should be used with caution in it's own separate section.  

5) The variable pctmuslim is among the more complete variables outside the core violations and fines dataset. We are not told the origin of this variable
either, so we have no idea of its veracity other than a common sense check. The thought behind including this variable may be that religion
and perhaps, Islam in particular, would have an impact on ethical or ethical (corrupt) behavior. It is not clear to me why Islam would be 
included and all other religions excluded. A more appropriate variable would be the percent of population which practices religion. It is 
also not clear to me that the ethics-religion association is necessarily as strong as some might think it is, though a more valid non-biased
variable could be used to test that relationship.  
"""
```{r}
remove(variable_description)
```

```{r results="asis"}

# This is assuming staff is better than cars, staff+spouse, total_cars.  Though I don't know if that's safe yet.

summary_table_output = cor_oneline[, c("country", "staff", "violations.pre", "violations.pos", "corruption")]
summary_table_output$mean_violations_per_staff.pre = summary_table_output$violations.pre/summary_table_output$staff
summary_table_output$mean_violations_per_staff.pos = summary_table_output$violations.pos/summary_table_output$staff

#TODO Sort, Round

kable(summary_table_output[1:10, c("country", "mean_violations_per_staff.pre", "mean_violations_per_staff.pos", "corruption")], 
      "latex", longtable = TRUE, booktabs = TRUE, 
      caption = "NOT YET SORTED BY VIOLATIONS - Top 10 Countries by Parking Violations", 
      col.names = c("Country", "Mean Violations per Staff Before 2002 Change", "Mean Violations per Staff After 2002 Change", "Corruption Index")) %>%
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position", "striped", "repeat_header"), row_label_position = 1)   



```



```{r}
remove(summary_table_output)
```
<!-- END UNIVARIATE ANALYSIS OF KEY VARIABLES --> 

<!-- START ANALYSIS OF KEY RELATIONSHIPS --> 
# Analysis of Key Relationships

<!-- END ANALYSIS OF KEY RELATIONSHIPS --> 

<!-- START ANALYSIS OF SECONDARY EFFECTS --> 
# Analysis of Secondary Effects

<!-- END ANALYSIS OF SECONDARY EFFECTS --> 


<!-- BEGIN CONCLUSION -->
# Conclusion

<!-- END CONCLUSION -->
